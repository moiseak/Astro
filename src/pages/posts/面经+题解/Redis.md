---
layout: /src/layouts/MarkdownPostLayout.astro
title: Redis
description: Redis的数据结构
pubDate: 2025-04-18
---
## Redis的数据结构
Redis 提供了丰富的数据类型，常见的有五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）**。

随着 Redis 版本的更新，后面又支持了四种数据类型：**BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）**。Redis 五种数据类型的应用场景：

- String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。
- List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
- Hash 类型：缓存对象、购物车等。
- Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
- Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

Redis 后续版本又支持四种数据类型，它们的应用场景如下：

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。


![image.png](https://raw.githubusercontent.com/moiseak/blogimg/main/img/20250501205751.png)

## Redis 某个 key 的 value 是 “1”，底层数据是什么

Redis 内部将只含整数的字符串自动编码为整数编码（`int`），当 `value` 在 64 位有符号范围内且为纯数字时，以整型节省空间。

## 为什么 zset 用跳表
- **内存友好**：跳表基于链表，通过多级索引加速查询，**内存访问模式更符合CPU缓存局部性**（指针跳跃更少）。
- **从内存占用上来比较，跳表比平衡树更灵活一些**。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。
- **在做范围查找的时候，跳表比平衡树操作要简单**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
- **从算法实现难度上来比较，跳表比平衡树要简单得多**。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。

## ZSet 除了跳表，还有其他底层格式吗

- **跳表 + 哈希表**：常规大规模有序集。
- **压缩列表/列表打包（ziplist/listpack）**：当成员数或成员长度小于阈值时，用于节省内存，但查询 O(n)。

## Redis集群脑裂，该怎么解决呢

Redis 集群脑裂（Network Partition）是指主从架构中，因网络分区导致主节点与从节点、哨兵（Sentinel）之间通信中断，进而引发 “双主” 现象（原主节点仍在运行，从节点被哨兵误判为主节点下线并晋升为新主节点），最终导致数据不一致。解决脑裂的核心是**预防为主、容错为辅**，通过配置限制和机制优化减少数据丢失风险。

### 核心结论：从 “限制旧主写入” 和 “优化判断机制” 双管齐下

脑裂的本质是网络分区后旧主节点仍接收写请求，而新主节点无法同步这些数据。解决思路是：**通过配置让旧主节点在失去多数从节点或哨兵连接时停止写入**，同时优化哨兵的判断逻辑减少误判，双方面阻止数据不一致扩大。

### 一、预防脑裂：限制旧主节点的写入权限

当网络分区发生时，若旧主节点无法与足够多的从节点或哨兵通信，强制其拒绝新写请求，从源头避免数据 “分叉”。核心依赖 Redis 的两个关键配置：

#### 1. 限制主节点需保持连接的从节点数量

通过`min-replicas-to-write`配置主节点可接受写操作的最小从节点数量（默认 0，即不限制）。

  

- 例：`min-replicas-to-write 1` 表示主节点必须至少与 1 个从节点保持同步，否则拒绝写请求。
- 作用：网络分区后，若旧主节点与所有从节点断开连接，会因不满足此条件而停止写入，避免新数据无法同步到新主节点。

#### 2. 限制从节点的最大同步延迟

通过`min-replicas-max-lag`配置从节点与主节点的最大允许延迟时间（单位秒，默认 10）。

  

- 例：`min-replicas-max-lag 5` 表示主节点仅在从节点的同步延迟≤5 秒时，才接受写请求。
- 作用：若从节点因网络问题同步延迟过大（超过 5 秒），主节点会拒绝写请求，避免写入的数据因延迟过高而在脑裂时丢失。

#### 关键配置参数说明

|配置参数|作用|建议值|注意事项|
|---|---|---|---|
|`min-replicas-to-write`|主节点接受写请求所需的最小从节点数量|1~(从节点总数 / 2 + 1)|需根据从节点数量调整，避免过于严格导致主节点频繁拒绝写入|
|`min-replicas-max-lag`|从节点与主节点的最大允许延迟（秒）|5~10 秒（根据业务对延迟的容忍度）|延迟设置过小将导致正常网络波动时主节点拒绝写入，影响可用性|

  

**配置效果**：网络分区后，旧主节点因无法与足够多的从节点保持 “低延迟同步”，会触发写拒绝，此时客户端写入旧主会失败（返回错误），从而避免数据写入旧主却无法同步到新主的问题。

### 二、优化哨兵判断机制：减少误判 “主节点下线” 的概率

哨兵（Sentinel）是主从切换的决策者，若其因网络分区误判主节点下线，会导致从节点被错误晋升。优化哨兵配置可降低误判风险：

#### 1. 提高客观下线（ODOWN）的判断门槛

哨兵判断主节点 “客观下线” 需获得**超过半数哨兵节点的同意**（默认需`quorum`参数指定的数量，如 3 个哨兵需至少 2 个同意）。

  

- 配置：`sentinel monitor mymaster 127.0.0.1 6379 2`（`2`表示需至少 2 个哨兵同意才能判定主节点客观下线）。
- 作用：增加哨兵间的共识门槛，减少单哨兵因网络问题误判的影响（需保证哨兵节点数量为奇数，如 3、5 个，避免投票平局）。

#### 2. 延长主观下线（SDOWN）的判断时间

哨兵默认通过`down-after-milliseconds`参数（默认 30000 毫秒，即 30 秒）判断主节点是否主观下线（单哨兵认为主节点无响应）。

  

- 建议：根据网络稳定性适当调大，如`down-after-milliseconds mymaster 50000`（50 秒）。
- 作用：避免因短暂网络抖动（如 10 秒超时）导致哨兵误判主节点下线，给网络恢复留出时间。

#### 3. 限制并行故障转移的数量

通过`sentinel parallel-syncs mymaster 1`配置故障转移时同时向新主节点同步数据的从节点数量（默认 1）。

  

- 作用：减少故障转移时的网络和新主节点负载，避免因同步压力过大导致新主节点响应延迟，间接降低脑裂后的数据同步风险。

### 三、脑裂发生后的处理：恢复数据一致性

若脑裂已发生（出现双主），需手动介入恢复数据，步骤如下：

  

1. **确认网络分区恢复**  
    等待网络恢复，确保所有节点（主、从、哨兵）重新通信，避免操作时再次分区。
    
2. **识别 “旧主节点” 和 “新主节点”**
    
    - 通过`info replication`命令查看节点角色：新主节点的`role`为`master`，且有从节点连接；旧主节点可能仍为`master`但从节点已断开。
    - 对比数据量：新主节点在脑裂期间可能也接收了部分写请求，需记录两边的新增数据。
3. **将旧主节点转为从节点，同步新主数据**
    
    - 在旧主节点执行`slaveof <新主节点IP> <新主节点端口>`，使其成为新主节点的从节点，通过全量复制同步新主节点数据（包括脑裂期间新主的写入）。
    - 注意：此操作会覆盖旧主节点在脑裂期间的新增数据，需提前备份旧主数据（如通过`bgsave`生成 RDB），手动合并必要数据。
4. **验证数据一致性**  
    通过`dbsize`、`keys *`等命令对比主从节点数据量，或使用`redis-check-rdb`工具检查 RDB 文件，确保同步完成后数据一致。
    

